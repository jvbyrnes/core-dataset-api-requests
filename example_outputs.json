{'totalHits': 407495, 'limit': 1, 'offset': 0, 'results': [{'acceptedDate': '', 'arxivId': '1811.04854', 'authors': [{'name': 'Costa, Frederico P'}, {'name': 'da Silva, Flavio S Correa'}, {'name': 'Iemma, Antonio F'}], 'citationCount': 0, 'contributors': [], 'outputs': ['https://api.core.ac.uk/v3/outputs/186289683'], 'createdDate': '2019-02-06T06:47:26', 'dataProviders': [{'id': 144, 'name': '', 'url': 'https://api.core.ac.uk/v3/data-providers/144', 'logo': 'https://api.core.ac.uk/data-providers/144/logo'}], 'depositedDate': '', 'abstract': 'Artificial intelligence and medicine have a longstanding and proficuous\nrelationship. In the present work we develop a brief assessment of this\nrelationship with specific focus on machine learning, in which we highlight\nsome critical points which may hinder the use of machine learning techniques\nfor clinical diagnosis and therapy advice in practice. We then suggest a\nconceptual framework to build successful systems to aid clinical diagnosis and\ntherapy advice, grounded on a novel concept we have coined drifting domains. We\nfocus on oncology to build our arguments, as this area of medicine furnishes\nstrong evidence for the critical points we take into account here.Comment: Submitted to Artificial Intelligence in Medicin', 'documentType': 'research', 'doi': None, 'downloadUrl': 'http://arxiv.org/abs/1811.04854', 'fieldOfStudy': None, 'fullText': 'ar\nX\niv\n:1\n81\n1.\n04\n85\n4v\n1 \n [c\ns.A\nI] \n 12\n N\nov\n 20\n18\nOn the practice of classification learning for clinical\ndiagnosis and therapy advice in oncology✩\nFlavio S Correa da Silvaa,d,∗, Frederico P Costab,d, Antonio F Iemmac,d\naDepartment of Computer Science, University of Sao Paulo, SP 05508090, Brazil\nbOncology Center, Hospital Sirio Libanes - Sao Paulo, SP 01308050\ncDepartment of Exact Sciences, University of Sao Paulo - Piracicaba, SP 13418900, Brazil\ndAutem Medical, Bedford NH 03110, USA\nAbstract\nArtificial intelligence and medicine have a longstanding and proficuous relation-\nship. In the present work we develop a brief assessment of this relationship with\nspecific focus on machine learning, in which we highlight some critical points\nwhich may hinder the use of machine learning techniques for clinical diagnosis\nand therapy advice in practice. We then suggest a conceptual framework to\nbuild successful systems to aid clinical diagnosis and therapy advice, grounded\non a novel concept we have coined drifting domains. We focus on oncology to\nbuild our arguments, as this area of medicine furnishes strong evidence for the\ncritical points we take into account here.\nKeywords: Machine Learning in Medicine; Supervised Learning; Drifting Domains\nHighlights:\n• The relationship between Artificial Intelligence and Medicine is reviewed,\nhighlighting the reasons why few research projects in this field are brought\nto medical practice.\n• Focusing on supervised learning applied to diagnosis and therapy plan in\noncology, we discuss possible means to overcome this issue.\n• We present how existing results related to sample complexity in machine\nlearning can be brought to this context to become guidelines to structure\nand explore results of clinical trials.\n✩\nDeclaration of interest: all three authors are partners of Autem Medical Research Lab\n(Brazil). We acknowledge support from Autem Medical Research to develop this work.\n∗Corresponding author\nEmail addresses: flavio.soares@autemmedical.com (Flavio S Correa da Silva),\nfrederico.costa@autemmedical.com (Frederico P Costa), anfiemma@gmail.com (Antonio F\nIemma)\nPreprint submitted to Elsevier November 13, 2018\n• We introduce the concept of drifting domains as a tool to refine and fine\ntune the analysis of results obtained with classification learning in our\ndomain of interest.\n1. Introduction\nArtificial intelligence and medicine have a longstanding and proficuous re-\nlationship, possibly started with the development of the MYCIN system in the\nearly 70s for therapy advice [9].\nMedicine has provided the field of artificial intelligence with a plethora of\nchallenging and appealing problems to be solved, particularly in clinical diag-\nnosis (“given a set of signs collected from a patient, select the best diagnosis”)\nand in therapy advice (“given an established diagnosis, select the best course\nof actions for treatment”). Artificial intelligence, in turn, has offered promising\ntechnologies for problem solving in the medical domain [7].\nThe field of oncology has proven to be particularly fit for modelling and\nanalysis based on artificial intelligence, at least prospectively [5, 3], due to two\nmajor reasons:\n1. Symptoms in oncology are frequently difficult to identify before later\nstages of the disease, and cancer can be treated most effectively if iden-\ntified at early stages of development. Signs of the disease can be diffuse\nand require high expertise to be selected, collected and analysed. Hence,\ntechnologies that can highlight evidence of cancer at early stages are most\nwelcome and challenging at the same time.\n2. Therapy in oncology can be frequently highly aggressive, as it can be based\non drugs which feature high toxicity and/or radiotherapy, which has severe\nside effects. Hence, technologies that can either refine therapy plans at a\npersonal level to minimise side effects or provide unequivocal evidence of\nthe efficacy of novel therapies are also most welcome.\nThe practical use of artificial intelligence in medicine, however, has occurred\nmore often in the management of supporting information, rather than in the\ndirect support of the activities of healthcare professionals: medical doctors have\nbeen able to augment their capabilities with the support of systems for knowl-\nedge representation and processing, as well as automated assistants to process\nlarge data chunks aid decision making. However, the practice of automated\ndiagnosis and therapy advice has hardly moved outwith research laboratories to\nreach everyday activities [1]. Some issues can explain why this has happened:\n• Medicine is strongly regulated by specialised organisations such as the\nFood and Drug Administration in the US and the European Medicines\nAgency and CE Mark certifying bodies in the European Economic Area.\nThe levels of detail and transparency required for the description of meth-\nods and techniques to be certified by these organisations has proven to be\nhard, costly and time consuming to achieve, and the effort to reach such\n2\nlevels in the description of novel techniques frequently stays beyond the\nscope of academic initiatives.\n• Empirical validation of novel methods and techniques for automated di-\nagnosis and therapy advice requires clinical trials which are highly costly,\nlabour and time consuming. In the medical domain, clinical trials are a re-\nquired practice for risk mitigation and trust building. Similar procedures\nare not usual in computer science, and the mismatch in required costs\nand resources sets apart research initiatives from within the contexts of\nmedical sciences and computer science.\nIn order to bridge the gap between laboratory experimentation and practice\nin the use of artificial intelligence technologies for clinical diagnosis and therapy\nadvice, these issues must be faced.\nIn recent years, the field of artificial intelligence has steered towards machine\nlearning, given its significant advances and results [4]. Following this trend, in\nthe present article we focus on machine learning – more specifically, supervised\nclassification learning, given that this particularly class of techniques can be\nformally characterised and analysed in detail – and how it can be explored to\nbuild systems for automated diagnosis and therapy advice which can be used\nin practice. We consider three specific points related to the issues mentioned in\nthe previous paragraphs:\n1. One reason for the recent praise to machine learning has been the claim\nthat it decreases subjectivity in artificial intelligence, as domain knowledge\nand expertise are replaced by statistically grounded data analysis. Critical\naspects of domain modelling, however, are still at the core of systems\ndevelopment based on machine learning. Accounting for regulatory issues\nand transparency requirements, we unveil these aspects and clarify how\nand why domain knowledge and human expertise – on the medical domain\nas well as on computational and statistical techniques – are central to the\ndesign of systems based on machine learning for the medical issues on\nwhich we are working.\n2. The demanding requirements of resources connected to clinical trials in-\ncrease the relevance of controlling sample complexity (in other words,\nextracting as much information as possible from samples which are kept\nas small as possible in order to train learning algorithms), which in turn\npoints to the importance of good domain modelling for the problems we\nare considering. For these reasons, we develop a careful analysis of our\npopulation of interest, accounting for the fact that controlled sample cardi-\nnality can be key to ensure the feasibility of proposed solutions in practice.\n3. Our population of interest features an interesting dynamics of evolution,\nwhich we believe has not been considered in detail in previous initiatives.\nWe take this dynamics into account and characterise the population as\na drifting domain, in the sense that it is permanently evolving, although\nalmost always in a smooth rate. We explore how drifting domains can\n3\nbe formally characterised to build accurate predictive models based on\nclassification learning.\nThe propositions and results presented in this article result from experiments\nunder development at Autem Medical Research, focusing on the development\nof novel technologies for cancer diagnosis and therapy. In this article we fo-\ncus on conceptual issues, and refer to our experiments mainly to illustrate our\narguments. In a future article we shall present our empirical results from the\nperspective of advances in clinical diagnosis and therapy advice.\nIn section 2 we characterise a method and model to build systems based on\nmachine learning for the problems we are considering in medicine, in which we\nhighlight the importance of domain knowledge and expertise for model design.\nIn section 3 we discuss specific aspects of our domain of interest, including how\nand why we can focus on populations with finite cardinality and how we can\nbuild lower bounds for population cardinality (aka sample complexity) given\nour requirements for precision and reliability. In section 4 we characterise our\nproposed notion of drifting domains and how it can be used to increase precision\nand reliability of our results. Finally, in section 5 we present a discussion and\nconclusions.\n2. Classification learning for diagnosis and therapy advice\nThe task of clinical diagnosis can be characterised as a set of steps:\n1. An individual patient p comes to the medical doctor. The doctor selects\na set of signs S1 to observe and analyse. The choice of the set S1 is based\non:\n• Previous experience and scholarly knowledge.\n• Tacit selection of a reference population P , assuming of course that\np ∈ P .\n2. Given the observations related to signs S1, the doctor builds a preliminary\nset of hypotheses D about the diagnostics of p. These hypotheses are\ndependent upon previous experience, scholarly knowledge and the refer-\nence population, which determine an (unknown yet clearly defined) upper\nbound on the precision and reliability of diagnostics.\n3. Hypotheses are prioritised according to\n• strength of evidence indicating each hypothesis, and\n• the severity of corresponding diseases.\nFollowing these priorities, for each hypothesis:\n(a) A second set of signs S2 is selected. Again, the choice of S2 is based\non previous experience, scholarly knowledge and the reference popu-\nlation.\n(b) Given the observations related to signs S2, the doctor tags the cor-\nresponding hypothesis as either possible or discarded.\n4\n4. The medical doctor then proceeds to perform information fusion about all\nhypotheses at hand and final decision about diagnostics.\nWe have focused on the automation of steps 1 to 3 in clinical diagnoses as\noutlined in the previous paragraphs. These steps inherently depend upon expert\nknowledge, regardless of the computational techniques that can be employed for\nautomation.\nRequired general steps to automate this procedure using supervised classifi-\ncation learning can be characterised as follows:\n1. Given an individual patient p, a reference population P is explicitly char-\nacterised, such that p ∈ P .\n2. Based on expert knowledge, a set or preliminary signs S1 is selected.\n3. An oracle Pˆ ⊆ P containing information about the correlation between\nsigns in S1 and hypotheses in D for diagnostics for population P is re-\ntrieved from a database of oracles. An oracle is a collection of pairs 〈~Si, Di〉\nin which ~Si ∈ S1 is a tuple of signs and D ∈ {⊤,⊥} is a corresponding\ndiagnostics as observed in a patient pi ∈ P .\nThe cardinality of oracle Pˆ (i.e. the number of patients pi ∈ Pˆ ) must be\nsufficiently large to ensure appropriate levels of precision and reliability\nof diagnostics performed about any patient p ∈ P , which correspond to a\nsufficiently large similarity level between empirical classifiers and the best\navailable classifier as determined by unknown upper bounds provided by\nhuman expertise.\n4. The correlation between signs and hypotheses is characterised with re-\nspect to a family of functions that best captures how decision procedures\ncan be optmised for this correlation. In machine learning and statistics\njargon, such families of functions are called kernel functions. The choice\nof the appropriate family of kernels (e.g. polynomial, gaussian, sigmoid\netc. [8]) is based on visual inspection of the correlation graphs and expert\nknowledge about the methods and techniques used to build models for\nmachine learning. The choice of a family of kernels determines another\n(unknown) upper bound on the precision and reliability of diagnostics.\n5. Hypotheses are prioritised and, for each hypothesis, a second set of signs\nS2 is selected, based on expert knowledge and the reference population.\n6. A second family of kernels is selected given the observed correlation be-\ntween S2 and the corresponding hypothesis.\n7. Samples of appropriate cardinality are selected from the population P ,\nconsidering lower bounds for the cardinality of samples as a function of\nthe required precision and reliability of diagnostics that can ensure suffi-\nciently high similarity between empirical classifiers and the best available\nclassifier. These lower bounds can be characterised based on existing the-\noretical results as detailed in section 3. If a sample has cardinality above\nthe identified upper bounds, we have statistical guarantees that obtained\nclassifiers will be, with high probability, sufficiently close to the best avail-\nable classifier given the upper bounds determined by the expert choices as\nidentified in the previous steps.\n5\n8. Automated decision procedures are built for the diagnosis of patient p ∈ P\nemploying a sample Pˆ of appropriate cardinality and the sets of signs S1\nand S2.\n9. Decision procedures are employed to build information to support the\nmedical doctor in diagnostics.\nSimilarly, the task of therapy advice can be characterised as a set of steps:\n1. An individual patient p comes to the medical doctor, featuring a previously\nidentified most likely diagnostics. The doctor selects a set of tests T to\nperform, in order to decide for a therapy plan. As in diagnosis, the set T\nis based on:\n• Previous experience and scholarly knowledge.\n• Tacit selection of a reference population P such that p ∈ P .\n2. Given the outcomes of T , the doctor builds a personalised therapy plan\nfor patient p. This plan can contain additional decision points in the form\nof IF-THEN rules.\n3. The effectiveness of the treatment is assessed based on empirical observa-\ntion of attributes which are determined based on expert knowledge and\nthe reference population.\nGeneral steps to automate this procedure can be characterised as follows:\n1. Given a patient p and corresponding most likely diagnostics, and given\nthe reference population P employed in the analysis, alternative therapy\nplans Ti are ranked according to previous empirical results. Ranking is\nbased on (most likely non-linear) correlation analyses between different\ntherapy plans and their corresponding effective measurements, which are\nbuilt using samples Pˆ ⊆ P of appropriate cardinality, which must be\nsuch that precision and reliability can be ensured with respect to the best\navailable information about therapy plans. The best available information\nabout different plans, in turn, is based on a history of empirical results.\nIn oncology, given the high mortality related to certain types of tumour,\nthese empirical results can be based on relatively small numbers of cases\nwhich are,in turn, described in great detail.\n2. The most highly ranked therapy is selected and applied on p.\nThis characterisation of both clinical diagnosis and therapy advice as sets\nof steps aims at the identification of the issues that impose limitations on the\nprecision and reliability of diagnosis and therapy advice:\n• The choice of the sets of signs S1 and S2, as well as the set of therapy\nplans T depends upon previous experience and scholarly knowledge (expert\nknowledge).\n• The choice of the reference population P to ground analyses also depends\non expert knowledge.\n6\n• The choice of the family of kernels to characterise the correlations between\nsigns and hypotheses, as well as between diagnostics and therapy plans,\ndepends upon experience and scholarly knowledge about statistical be-\nhaviour of specified random variables with respect to stochastic decision\nprocedures in the domain of interest.\nThese limitations are imposed upon the best possible decision procedures\nfor patients in the population P . Additionally,\n• The cardinality of the samples used to build empirical estimates for the\nbest possible decision procedures is determined given lower bounds pro-\nvided by statistical analysis.\nExplicit account of these limitations and their reasons are useful to clarify\nthat:\n1. Most limitations in the quality of automated clinical diagnosis and ther-\napy advice originate from previous experience of medical doctors, schol-\narly knowledge and the reference population employed to make decisions.\nThese issues are not particular to automated systems and are at place in\nstandard medical practice.\n2. Limitations in precision and reliability of decisions due to sample cardinal-\nity can be safely bounded provided that we have access to sufficiently large\nsamples. These bounds, as detailed in the following section, are grounded\non scrutinous mathematical analysis.\nMoreover,\n3. The dynamics of reference populations can be modelled and taken into\naccount explicitly in decision procedures. In section 4 we introduce a\nmethodology to provide bounds in precision of decisions given heuristic\nestimates of the dynamics of the evolution of reference populations.\nIn the following sections we discuss in detail the lower bounds for the cardi-\nnality of samples Pˆ ⊆ P to estimate decision procedures, as well as the dynamics\nof the reference populations P .\n3. Domain characterisation\nThe initial problem we consider, as characterised in the previous sections, is\nas follows: given a reference population P of patients featuring sufficiently high\nhomogeneity with respect to the correlation between observable signs ∈ S and\ncorresponding diagnoses ∈ D, we wish to determine a minimal cardinality N\nfor oracles Pˆ of the form Pˆ = {〈~v1, di〉, . . . , 〈~vN , dN 〉} such that for the indices\n1, . . .N we have that p1, . . . pN ∈ P , each ~vi is a tuple of values of signs ∈ S\ncorresponding to observations about patient pi, and di ∈ {⊤,⊥} is a confirmed\ndiagnostics for patient pi with respect to a disease d ∈ D, in which ⊤ indicates\nconfirmed disease and ⊥ indicates refuted disease.\n7\nWe assume a high correlation between values of signs ~vi and diagnostics\ndi. We do not assume, however, that this correlation is perfect (which would\ncorrespond to a fully deterministic power, at least in a theoretical limit in which\ninformation about all patients in P is available, to diagnose disease di given\nobserved values of signs ~vi). The set {〈~v1, d1〉, . . . , 〈~v|P |, d|P |} of all pairs 〈signs,\ndiagnostics〉 ∈ P can, therefore, be partially inconsistent, amounting for an\n(unknown yet determined) upper bound on the precision of diagnoses as well\nas definition of therapy plans. This upper bound determines the best available\nclassifiers. Our task is to build empirical classifiers based on oracles Pˆ which\nare provably sufficiently similar to the best available classifiers.\nThe theory of Probably Approximately Correct Learning [10], as further ex-\ntended to cope with partial inconsistencies [2, 6], can provide us with lower\nbounds for the cardinality of ~P as a function of:\n• |~V|: the cardinality of the valued signs space. Assuming that each sign\ns ∈ S can have a finite set of values {v1, . . . , vns} with cardinality ns, we\nhave that |~V| =\n∏\ns∈S ns.\n• ǫ: precision, determined as an upper bound for the acceptable disagree-\nment between an empirical classifier and the best available classifier. For\nexample, if ǫ = 0.1, then the probability that, given a tuple of values of\nsigns ~v, the empirical classifier and the best available classifier provide the\nsame diagnostics d ∈ {⊤,⊥} is at least 90%.\n• δ: reliability, as an upper bound for the risk to build a classifier whose\nprecision parameter is above the specified value ǫ. For example, if δ = 0.2\nand ǫ = 0.1, then there is a probability below 20% to select a random\nclassifier built using any oracle Pˆ with a disagreement below 90% with\nrespect to the best available classifier.\nFollowing [6], we can define a lower bound for the cardinality of Pˆ (denoted\nas |Pˆ |) as:\n|~P | ≥\n(ln|~V|+ln 2\nδ\n)\n2ǫ2\nThe same lower bound applies for diagnosis and for therapy advice, if we\nuse, for example, Support Vector Classification for diagnosis and Support Vector\nCorrelation for therapy advice [6].\nAs an example, assuming |~V| ≈ 150, we will have ln|~V| ≈ 5. This is a\nrealistic assumption, considering the number of parameters and corresponding\nvalues which are usually considered by a medical doctor for the tasks under\nconsideration here.\nEmploying this value, estimates can be obtained for |~P | given values for ǫ\nand δ as presented in Table 1.\n8\n|Pˆ |\nǫ\n0.1 0.2 0.3\nδ\n0.1 400 366 346\n0.2 100 92 87\n0.3 45 41 39\nTable 1: Lower bounds for |~P | given ǫ and δ assuming |~V| ≈ 150.\nAs a concrete illustration, according to Table 1, if we wish to have a prob-\nability below 20% that a classifier will be built with disagreement above 10%\nwith respect to the best available classifier, then we need to have access to a\nreference population with at least 100 patients.\nThese results bring existing methods and techniques to the context of clin-\nical diagnosis and therapy advice, and provide medical doctors with concrete\nparameters and specifications to allow the development of systems based on clas-\nsification learning for direct support of their activities. They are based, however,\non an implicit assumption that any reference population and corresponding or-\nacles for any disease under consideration are static. This assumption is not\nobserved in practice:\n• Patients pass away, and new patients appear all the time.\n• Environmental factors (e.g. pollution rates, dietary habits, stress levels)\naffect the reference population and the extent to which observed signals\ncorrelate with diagnoses.\nFor these reasons, it is reasonable to assume that the reference population\nundergoes small updates all the time. In order to take into account these up-\ndates, we introduce in the next section the concept of drifting domains and show\nhow it can be employed to build more refined and precise estimates for clinical\ndiagnosis and therapy advice.\n4. Drifting domains\nSome implicit assumptions about our domain have been used in the previous\nsections:\n1. Our domain is finite, even though it can be large. This way, technical\nassumptions about probability distributions and logical deductions can be\nsimplified respectively to discrete distributions and propositional reason-\ning.\n2. Our domain is static and fixed, even though we may not have complete\ninformation about each and every element of the domain.\nWe challenge the second assumption, given our previous consideration that\nour domain of interest undergoes permanent updates. We assume that these\n9\nupdates are gradual and smooth, as we believe that this assumption is realistic\nand it simplifies our analyses.\nIn order to characterise this assumption, we denote domains in which these\ncharacteristics are found drifting domains. A drifting domain is, therefore:\n• A finite domain whose cardinality can be unknown and is permanently\nupdated with small random values which can be positive or negative.\n• Such that a fixed set of signs characterise each and all elements in the\ndomain.\n• Such that each sign admits a finite set of values.\n• Such that the value of each sign associated to each element in the domain\nis permanently updated, in such way that no “sudden jump” in a value\ncan be observed.\nGiven these assumptions, and considering that an undetermined time in-\nterval occurs between data is collected to build oracles, and that oracles are\nused for classification of patients, then one reasonable strategy to build more\naccurate oracles is to assume that, for each value of each sign collected from a\npatient, the actual present value of that sign can be a different value “around”\nthe observed value.\nOne possible way to formalise this strategy is to assume that, for each ob-\nserved value of a sign, the actual present value is going to be within an interval\ncentred in the observed value. In order to keep calculations simple, we can\nassume a probability distribution around the observed value, such as e.g. a\nstandardised normal distribution in which the mean value is the observed value.\nIf, additionally, all values are assumed to be discrete approximations of real\nscalar values, we can further assume that present the values of a sign are, with\nhigh probability (above 95%), within two standard deviations below and above\nthe observed value.\nThis way, for each observed value v˜ we build the interval [v˜−, v˜+] such that\nv˜− = v˜−2σ and v˜+ = v˜+2σ. If we consider the extreme values in this interval,\nwe have for each observed value v˜ the two values {v˜−, v˜+}.\nGiven |S| as the cardinality of the set of signs, and given one specific obser-\nvation about one patient belonging to an oracle, reasoning based on extremes\nof a surrounding interval for the value of each sign builds 2|S| alternative “ver-\nsions” of that observation. Assuming that the cardinality of a sample is |Pˆ |, we\nthen have a collection of “possible worlds” W whose cardinality is defined as:\n|W| = |Pˆ |2|S|\nIf we build one empirical classifier for each possible world, we can test the\nobservations of a new patient with respect to |W| different classifiers. Two\npossibilities can occur:\n10\n1. All classifiers agree on the diagnostics for the patient. In this case, this\ndiagnostics is strengthened by being tested considering all variations of\nthe observed sample given the drifting domain under consideration.\n2. We obtain conflicting classifiers across the possible worlds. In this case,\nupon final decision of the medical doctor, three different strategies can be\nconsidered:\n(a) Cautious strategy: the doctor concludes that data is inconsistent\nand/or insufficient for decision and requires a second cycle of ob-\nservations, selection of a reference population etc. hoping to be able\nto resolve the conflict.\n(b) Asymmetric strategy: in diagnosis false negatives can be more harm-\nful than false positives, i.e. it can be more damaging to diagnose\nan unhealthy patient as healthy than the opposite. In this case, if\nat least one classifier diagnoses the patient as unhealthy, following\nthis strategy the patient can be taken for further examination as\npotentially unhealthy.\n(c) Uncertainty-based strategy: some heuristics can be built to assess un-\ncertainty degrees corresponding to the conflicting outcomes of clas-\nsifiers. For example, some voting procedure can be adopted, such\nthat the confidence on a diagnostics is based on the proportion of\nclassifiers that indicate that diagnostics.\nFor diagnosis, any of the three strategies can be adopted. For therapy ad-\nvice, however, only the first strategy makes sense, given that the selection\nof the wrong therapy plan is potentially harmful in a symmetric way.\n5. Conclusion\nIn this article we have built considerations on how to close the gap between\nlaboratory experimentation and medical practice on using classification learning\nfor clinical diagnosis and therapy advice, with a specific focus on oncology.\nMore specifically, we have provided an explicit and detailed account of how\nsystems for classification learning can be inserted into the activities workflow\nof a medical doctor to support diagnosis and therapy advice. Given that an\nimportant barrier to the application of machine learning techniques in medicine\ncan be the requirements of large volumes of data, which can point to the ne-\ncessity of building and running prohibitively costly clinical trials, we have also\ndeveloped an analysis of sample complexity estimates to build oracles to train\nsystems based on supervised learning, and suggested a pathway to build ora-\ncles based on clinical trials of viable dimensions. Finally, we have considered\nthe dynamics of populations from which samples can be taken, and proposed\na strategy to refine the analysis of classification results that take into account\nthis dynamics, based on a proposed notion of drifting domains.\nThe considerations we have built here are based on actual experiments un-\nder development at Autem Medical Research, where we have worked on novel,\nlesser aggressive therapies for certain types of cancer and on novel, non-invasive,\n11\nspeedy and low cost technologies for early diagnosis of cancer. Following the\nguidelines presented here, we have been able to build classifiers to make diag-\nnosis with error rates below 25% based on oracles such that |Pˆ | ≤ 90. These\nclassifiers are, at present, undergoing scrutinous analysis and shall be described\nin a specific article in the near future.\nReferences\n[1] Chen, J. H., Asch, S. M., 2017. Machine learning and prediction in\nmedicine: beyond the peak of inflated expectations. The New England\njournal of medicine 376 (26), 2507.\n[2] Haussler, D., 1992. Decision theoretic generalizations of the PAC model for\nneural net and other learning applications. Information and Computation\n100 (1), 78–150.\n[3] Kaplan, H., Berry, A., Rinn, K., Ellis, E., Birchfield, G., Wahl, T., Liu, X.,\nTameishi, M., Beatty, J. D., Dawson, P., Mehta, V., Holman, A., Atwood,\nM., Alexander, S., Bonham, C., Summers, L., Khalil, I., Hayete, B., Wuest,\nD., Zheng, W., Liu, Y., Wang, X., Brown, T. D., 2018. Abstract 5299: Ma-\nchine learning approach to personalized medicine in breast cancer patients:\nDevelopment of data-driven, personalized, causal modeling through iden-\ntification and understanding of optimal treatments for predicting better\ndisease outcomes. Cancer Research 78 (13 Supplement), 5299–5299.\n[4] Kononenko, I., 2001. Machine learning for medical diagnosis: history, state\nof the art and perspective. Artificial Intelligence in Medicine 23 (1), 89–109.\n[5] Kourou, K., Exarchos, T. P., Exarchos, K. P., Karamouzis, M. V., Fo-\ntiadis, D. I., 2015. Machine learning applications in cancer prognosis and\nprediction. Computational and structural biotechnology journal 13, 8–17.\n[6] Mohri, M., Rostamizadeh, A., Talwalkar, A., 2012. Foundations of machine\nlearning. MIT press.\n[7] Peek, N., Combi, C., Marin, R., Bellazzi, R., 2015. Thirty years of artificial\nintelligence in medicine (AIME) conferences: A review of research themes.\nArtificial intelligence in medicine 65 (1), 61–73.\n[8] Scholkopf, B., Smola, A. J., 2001. Learning with kernels: support vector\nmachines, regularization, optimization, and beyond. MIT press.\n[9] Shortliffe, E. H., Axline, S. G., Buchanan, B. G., Merigan, T. C., Cohen,\nS. N., 1973. An artificial intelligence program to advise physicians regarding\nantimicrobial therapy. Computers and Biomedical Research 6 (6), 544–560.\n[10] Valiant, L. G., 1984. A theory of the learnable. Communications of the\nACM 27 (11), 1134–1142.\n12\n', 'id': 54170389, 'identifiers': [{'identifier': '1811.04854', 'type': 'ARXIV_ID'}, {'identifier': 'oai:arxiv.org:1811.04854', 'type': 'OAI_ID'}, {'identifier': '186289683', 'type': 'CORE_ID'}], 'title': 'On the practice of classification learning for clinical diagnosis and\n  therapy advice in oncology', 'language': {'code': 'en', 'name': 'English'}, 'magId': None, 'oaiIds': ['oai:arxiv.org:1811.04854'], 'publishedDate': '2018-11-12T00:00:00', 'publisher': '', 'pubmedId': None, 'references': [], 'sourceFulltextUrls': ['http://arxiv.org/abs/1811.04854'], 'updatedDate': '2020-12-24T14:41:52', 'yearPublished': 2018, 'journals': [], 'links': [{'type': 'download', 'url': 'http://arxiv.org/abs/1811.04854'}, {'type': 'display', 'url': 'https://core.ac.uk/works/54170389'}]}], 'searchId': '2bab51b371973d26e3d2e8958be52933'}
------------------------------------------------------------
{'totalHits': 9, 'limit': 1, 'offset': 0, 'results': [{'identifiers': ['oai:doaj.org/journal:096fdfe93e134f048dcb63c9f89d2d73', 'issn:1532-4435', 'issn:1533-7928', 'url:https://doaj.org/toc/1533-7928'], 'language': 'English', 'publisher': 'JMLR', 'subjects': ['computer science', 'Electronic computers. Computer science', 'QA75.5-76.95', 'Instruments and machines', 'QA71-90', 'Mathematics', 'QA1-939', 'Science', 'Q'], 'dataProviderId': '645', 'title': 'Journal of Machine Learning Research'}]}
------------------------------------------------------------
{'totalHits': 1, 'limit': 10, 'offset': 0, 'results': [{'id': 14309, 'openDoarId': None, 'name': 'National Institute of Informatics, Center of Dataset Sharing and Collaborative Research: NII DSC Reference Portal / 国立情報学研究所', 'email': '', 'oaiPmhUrl': 'https://dsc.repo.nii.ac.jp/oai', 'homepageUrl': 'https://dsc.repo.nii.ac.jp', 'software': 'WEKO', 'metadataFormat': 'oai_dc', 'createdDate': '2019-09-23T00:00:00+01:00', 'location': {'countryCode': 'JP', 'latitude': 0, 'longitude': 0}, 'logo': 'https://api.core.ac.uk/data-providers/14309/logo', 'type': 'REPOSITORY', 'rorId': None, 'institutionName': None, 'aliases': [], 'otherIdentifiers': None}]}
